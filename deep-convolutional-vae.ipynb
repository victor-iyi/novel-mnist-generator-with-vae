{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import ImageDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'datasets/flowers/'\n",
    "save_data = 'datasets/saved/data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 of 5 class labels & 799 of 799 images"
     ]
    }
   ],
   "source": [
    "data = ImageDataset(data_dir=data_dir, grayscale=False, flatten=True, logging=True)\n",
    "# data.create()\n",
    "# data.save(save_data, force=True)\n",
    "data = data.load(save_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3303, 7500) (3303, 5) (367, 7500) (367, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizie = 50 Channels = 3\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "image_size = data.size\n",
    "image_channel = data.channel\n",
    "image_size_flat = image_size * image_size * image_channel\n",
    "print('Sizie = {:,} Channels = {:,}'.format(image_size, image_channel))\n",
    "\n",
    "# Network\n",
    "filter_size = 5\n",
    "conv1_size = 32\n",
    "conv2_size = 64\n",
    "fc1_size = 1024\n",
    "hidden_dim = 256\n",
    "latent_dim = 128\n",
    "keep_prob = 0.8\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-3\n",
    "batch_size = 24\n",
    "iterations = 10000\n",
    "log_interval = 100\n",
    "save_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# weights\n",
    "def weight(shape, name):\n",
    "    initial = tf.truncated_normal(shape=shape, mean=0, stddev=0.4)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "# biases\n",
    "def bias(shape, name):\n",
    "    initial = tf.zeros(shape=[shape])\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def leakyReLU(X, alpha=0.3):\n",
    "    return tf.maximum(X, tf.multiply(X, alpha))\n",
    "\n",
    "# convolutional block\n",
    "def conv(X, W, b):\n",
    "    layer = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    layer = layer + b  # add bias\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    layer = tf.contrib.layers.batch_norm(layer)\n",
    "    return layer\n",
    "\n",
    "# deconvolutional block\n",
    "def deconv(X, W, b):\n",
    "    pass\n",
    "\n",
    "# fully connected block\n",
    "def dense(X, W, b, activation=leakyReLU, batch_norm=False):\n",
    "    layer = tf.matmul(X, W) + b\n",
    "    if activation:\n",
    "        layer = activation(layer)\n",
    "    if batch_norm:\n",
    "        layer = tf.contrib.layers.batch_norm(layer)\n",
    "    return layer\n",
    "\n",
    "# flatten\n",
    "def flatten(layer):\n",
    "    shape = layer.get_shape()\n",
    "    features = np.array(shape[1:4], dtype=int).prod()\n",
    "    layer = tf.reshape(layer, [-1, features])\n",
    "    return layer, features\n",
    "\n",
    "# Plot images in grid\n",
    "def plot_images(imgs, size=28, name=None, **kwargs):\n",
    "    grid = int(np.sqrt(len(imgs)))\n",
    "    fig, axes = plt.subplots(grid, grid)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    if name:\n",
    "        plt.suptitle(name)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = imgs[i].reshape([image_size, image_size, image_channel])\n",
    "        ax.imshow(img, **kwargs)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encoder(image):\n",
    "    with tf.name_scope('encoder'):\n",
    "        image = tf.reshape(image, [-1, image_size, image_size, image_channel])\n",
    "        # 1st conv layer\n",
    "        W_conv1 = weight(shape=[filter_size, filter_size, image_channel, conv1_size], name='W_conv1')\n",
    "        b_conv1 = bias(shape=conv1_size, name='b_conv1')\n",
    "        conv1 = conv(image, W_conv1, b_conv1)\n",
    "        # 2nd conv layer\n",
    "        W_conv2 = weight(shape=[filter_size, filter_size, conv1_size, conv2_size], name='W_conv2')\n",
    "        b_conv2 = bias(shape=conv2_size, name='b_conv2')\n",
    "        conv2 = conv(conv1, W_conv2, b_conv2)\n",
    "        # Flatten\n",
    "        flattened, feature = flatten(conv2)\n",
    "        # Fully connected 1\n",
    "        W_fc1 = weight(shape=[feature, fc1_size], name='W_fc1')\n",
    "        b_fc1 = bias(shape=fc1_size, name='b_fc1')\n",
    "        fc1 = dense(flattened, W_fc1, b_fc1, batch_norm=True)\n",
    "        # Fully connected 2\n",
    "        W_fc2 = weight(shape=[fc1_size, hidden_dim], name='W_fc2')\n",
    "        b_fc2 = bias(shape=hidden_dim, name='b_fc2')\n",
    "        fc2 = dense(fc1, W_fc2, b_fc2, batch_norm=True)\n",
    "        # Mean\n",
    "        W_mean = weight(shape=[hidden_dim, latent_dim], name='W_mean')\n",
    "        b_mean = bias(shape=latent_dim, name='b_mean')\n",
    "        mean = dense(fc2, W_mean, b_mean, activation=None, batch_norm=True)\n",
    "        # Stddev\n",
    "        W_stddev = weight(shape=[hidden_dim, latent_dim], name='W_stddev')\n",
    "        b_stddev = bias(shape=latent_dim, name='b_stddev')\n",
    "        stddev = 0.5 * dense(fc2, W_stddev, b_stddev, activation=None, batch_norm=True)\n",
    "        # Random noise\n",
    "        noise = tf.random_normal(shape=[1, latent_dim])\n",
    "        encoded = mean + tf.multiply(noise, tf.exp(0.5 * stddev))\n",
    "        return encoded, mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoder(encoded):\n",
    "    with tf.name_scope('decoder'):\n",
    "        # Fully connected 1\n",
    "        W_fc1 = weight(shape=[latent_dim, hidden_dim], name='W_fc1')\n",
    "        b_fc1 = bias(shape=hidden_dim, name='b_fc1')\n",
    "        fc1 = dense(encoded, W_fc1, b_fc1, activation=leakyReLU, batch_norm=True)\n",
    "        # Fully connected 2\n",
    "        W_fc2 = weight(shape=[hidden_dim, fc1_size], name='W_fc2')\n",
    "        b_fc2 = bias(shape=fc1_size, name='b_fc2')\n",
    "        fc2 = dense(fc1, W_fc2, b_fc2, activation=leakyReLU, batch_norm=True)\n",
    "        # Reconstruction\n",
    "        W_rec = weight(shape=[fc1_size, image_size_flat], name='W_rec')\n",
    "        b_rec = bias(shape=image_size_flat, name='b_rec')\n",
    "        decoded = dense(fc2, W_rec, b_rec, activation=tf.nn.sigmoid)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, image_size_flat])\n",
    "\n",
    "encoded, mean, stddev = encoder(X)\n",
    "decoded = decoder(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reconstruction loss, KL-Divergence & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rec_loss = tf.reduce_sum(tf.squared_difference(decoded, X), reduction_indices=1)\n",
    "kl_term = -0.5 * tf.reduce_sum(1.0 + 2.0 * stddev - tf.square(mean) - tf.exp(2.0 * stddev), reduction_indices=1)\n",
    "loss = tf.reduce_mean(rec_loss + kl_term)\n",
    "\n",
    "global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensorflow's `tf.Session()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorboard_dir = 'tensorboard/'\n",
    "logdir = os.path.join(tensorboard_dir, 'log')\n",
    "save_path = 'models/'\n",
    "\n",
    "tf.summary.histogram('rec_loss', rec_loss)\n",
    "tf.summary.histogram('kl_term', kl_term)\n",
    "\n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('kl_term_mean', tf.reduce_mean(kl_term))\n",
    "tf.summary.scalar('rec_loss_mean', tf.reduce_mean(rec_loss))\n",
    "rec_img = tf.reshape(decoded, [-1, image_size, image_size, image_channel])\n",
    "tf.summary.image('rec_img', rec_img, max_outputs=4)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "# maybe restore last checkpoint\n",
    "if tf.gfile.Exists(save_path):\n",
    "    try:\n",
    "        sys.stdout.write('\\rAttempting to restore the last checkpoint.\\n')\n",
    "        last_ckpt = tf.train.latest_checkpoint(save_path)\n",
    "        saver.restore(sess=sess, save_path=last_ckpt)\n",
    "        sys.stout.write('\\rRestored checkpoint from {}'.format(last_ckpt))\n",
    "    except:\n",
    "        sys.stderr.write('INFO: {}'.format(e))\n",
    "else:\n",
    "    tf.gfile.MakeDirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 999\tKL-Term: 116.2304\tRec loss: 108501920.0000\tLoss:108502040.0000\tTrain time: 0:08:25.018155"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7500 into shape (50,50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-19cd788013ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     sys.stdout.write('\\rIter: {:,}\\tKL-Term: {:.4f}\\tRec loss: {:.4f}\\tLoss:{:.4f}\\tTrain time: {}'.format(\n\u001b[1;32m     15\u001b[0m         i, np.mean(_kl_loss), np.mean(_rec_loss), _loss, dt.datetime.now() - start_time))\n",
      "\u001b[0;32m<ipython-input-9-335230821c52>\u001b[0m in \u001b[0;36mplot_images\u001b[0;34m(imgs, size, name, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7500 into shape (50,50)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEVCAYAAADjHF5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12495e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "for i in range(1, iterations+1):\n",
    "    batch = data.next_batch(batch_size=batch_size)[0]\n",
    "    _, _kl_loss, _i_global, _loss = sess.run([train_step, kl_term, i_global, loss], \n",
    "                                             feed_dict={X: batch})\n",
    "    if i % save_interval == 0:\n",
    "        saver.save(sess=sess, save_path=save_path, global_step=global_step)\n",
    "        summary = sess.run(merged, feed_dict={X: batch})\n",
    "        writer.add_summary(summary=summary, global_step=global_step)\n",
    "    if i % log_interval == 0:\n",
    "        random = [np.random.normal(0, 1, latent_dim) for _ in range(9)]\n",
    "        imgs = sess.run(decoded, feed_dict={encoded: random})\n",
    "        plot_images(imgs, size=image_size, name='Test images', cmap='binary', interpolation='bicubic')\n",
    "    sys.stdout.write('\\rIter: {:,}\\tGlobal step: {:,}\\tLoss:{:.4f}\\tTrain time: {}'.format(\n",
    "        i+1, _i_global, _loss, dt.datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
